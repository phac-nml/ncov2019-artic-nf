// Global default params, used in configs
params {
    //- Required workflow flags
    prefix = false
    basecalled_fastq = ''

    //- Scheme input params
    scheme_repo_url = 'https://github.com/phac-nml/primer-schemes.git'
    scheme = 'nCoV-2019'
    scheme_version = 'freed'
    //-- Use local scheme if given - Still needs to follow above convention
    //--  Check the README for more info on structure
    local_scheme = ''

    //- Nanopore options
    //-- Read count filtering
    min_reads_per_barcode = 100
    min_reads_guppyplex = 10
    //-- Read length filtering - will be based on amplicon scheme and is done by artic guppyplex
    min_length = 800
    max_length = 1600
    //-- Artic minion args
    normalise = 500
    no_frameshift = false // VCF filter `no-frameshift` arg checks for %3==0 allele calls
    params.clair3_model = null // clair3 model does not need to be provided if the information is in the fastq headers

    //- Config for running ncov-tools
    ncov = "$baseDir/extra_data/config.yaml"

    //- Nextclade
    nextclade_dataset = "sars-cov-2"
    nextclade_tag = "latest"

    //- Metadata and IRIDA Uploads
    //-- Metadata is supplied with `--irida metadata.tsv` and requires specific columns. See README
    irida = ''
    //-- Upload to IRIDA needs a config file along with the irida metadata TSV file. See README
    upload_irida = ''

    //- Additional QC checks and files
    skip_correct_n = false
    pcr_primers = "$baseDir/extra_data/pcr_primers.bed"
    sequencing_technology = 'Nanopore'

    //- Typing module params
    gff = ''
    //-- Typing frequency threshold to call aa consequences of variant. Set to ivarFreqThreshold for consistency with consensus
    csq_af_threshold = 0.75
    //-- Minimum coverage depth to call aa consequences of variant. Set to ivarMinDepth for consistency with consensus
    csq_dp_threshold = 10

    //- Other boilerplate options
    outdir = './results'
    help = false
    profile = false // To warn if someone accidentaly uses 2 -- to set a profile
    tracedir = "${params.outdir}/pipeline_info"

    //- cache option makes it a bit easier to set conda or singularity cacheDir
    cache = null

    //- Max resource options
    max_memory = '256.GB'
    max_cpus = 16
    max_time = '120.h'
}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

// Supported profiles
profiles {
    conda {
        conda.enabled          = true
        conda.useMamba         = false
        includeConfig 'conf/conda.config'
        if ( params.cache ) {
            conda.cacheDir = params.cache
        }
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    mamba {
        conda.enabled          = true
        conda.useMamba         = true
        includeConfig 'conf/conda.config'
        if ( params.cache ) {
            conda.cacheDir = params.cache
        }
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    // No docker/singularity at the moment due to some steps
    slurm {
        process.executor = 'slurm'
    }
    lsf {
        process.executor = 'lsf'
    }
    //NML Canada Specific Config
    nml {
        includeConfig 'conf/nml.config'
    }
    // Test config to run tests on github
    test {
        includeConfig 'conf/test.config'
    }
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

def timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.tracedir}/execution_timeline_${timestamp}.html"
}
report {
    enabled = true
    file    = "${params.tracedir}/execution_report_${timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.tracedir}/execution_trace_${timestamp}.txt"
}
dag {
    enabled = false
    file    = "${params.tracedir}/pipeline_dag_${timestamp}.html"
}

manifest {
    name            = 'phac-nml/ncov2019-artic-nf'
    author          = 'Rewritten by PHAC-NML - Darian Hole, original by Matt Bull'
    description     = 'Nextflow for running the Artic ncov2019 pipeline'
    mainScript      = 'main.nf'
    nextflowVersion = '>=22.10.0'
    version         = '3.0.0'
    doi             = ''
    defaultBranch   = 'master'
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
